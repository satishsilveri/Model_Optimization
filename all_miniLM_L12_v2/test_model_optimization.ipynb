{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVShJ0OGrl8P",
        "outputId": "394b58c8-3e99-4891-fd53-09c5be9d1025"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (4.64.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (0.14.1+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.7.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (3.7)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.25.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=d9c9f232ff058aa8cfdec74423d2064a85f822602fe1bf27decc1f6473bf186d\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/6f/8c/d88aec621f3f542d26fac0342bef5e693335d125f4e54aeffe\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: tokenizers, sentencepiece, huggingface-hub, transformers, sentence-transformers\n",
            "Successfully installed huggingface-hub-0.12.1 sentence-transformers-2.2.2 sentencepiece-0.1.97 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ],
      "source": [
        "pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"optimum[onnxruntime]==1.5.0\" transformers evaluate mkl-include mkl --upgrade\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRB4lYl0rzWs",
        "outputId": "26917e5c-8501-4e22-d8e6-dc601f8a6973"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optimum[onnxruntime]==1.5.0\n",
            "  Downloading optimum-1.5.0-py3-none-any.whl (187 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.2/187.2 KB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.1)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 KB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mkl-include\n",
            "  Downloading mkl_include-2023.0.0-py2.py3-none-manylinux1_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mkl in /usr/local/lib/python3.8/dist-packages (2019.0)\n",
            "Collecting mkl\n",
            "  Downloading mkl-2023.0.0-py2.py3-none-manylinux1_x86_64.whl (254.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.4/254.4 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from optimum[onnxruntime]==1.5.0) (0.12.1)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.8/dist-packages (from optimum[onnxruntime]==1.5.0) (1.13.1+cu116)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 KB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from optimum[onnxruntime]==1.5.0) (1.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from optimum[onnxruntime]==1.5.0) (23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from optimum[onnxruntime]==1.5.0) (1.21.6)\n",
            "Collecting datasets>=1.2.1\n",
            "  Downloading datasets-2.9.0-py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.8/462.8 KB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx\n",
            "  Downloading onnx-1.13.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.9.0\n",
            "  Downloading onnxruntime-1.14.0-cp38-cp38-manylinux_2_27_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf==3.20.1\n",
            "  Downloading protobuf-3.20.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2023.1.0)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.3.5)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.3.6)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: intel-openmp==2023.* in /usr/local/lib/python3.8/dist-packages (from mkl) (2023.0.0)\n",
            "Collecting tbb==2021.*\n",
            "  Downloading tbb-2021.8.0-py2.py3-none-manylinux1_x86_64.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets>=1.2.1->optimum[onnxruntime]==1.5.0) (3.8.4)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets>=1.2.1->optimum[onnxruntime]==1.5.0) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.8.0->optimum[onnxruntime]==1.5.0) (4.5.0)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.8/dist-packages (from onnxruntime>=1.9.0->optimum[onnxruntime]==1.5.0) (23.1.21)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.1.97)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 KB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx\n",
            "  Downloading onnx-1.12.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->optimum[onnxruntime]==1.5.0) (1.2.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=1.2.1->optimum[onnxruntime]==1.5.0) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=1.2.1->optimum[onnxruntime]==1.5.0) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=1.2.1->optimum[onnxruntime]==1.5.0) (1.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=1.2.1->optimum[onnxruntime]==1.5.0) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=1.2.1->optimum[onnxruntime]==1.5.0) (22.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=1.2.1->optimum[onnxruntime]==1.5.0) (3.0.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=1.2.1->optimum[onnxruntime]==1.5.0) (1.3.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n",
            "Installing collected packages: tbb, mkl-include, xxhash, urllib3, protobuf, multiprocess, mkl, humanfriendly, onnx, coloredlogs, responses, onnxruntime, datasets, evaluate, optimum\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.19.6\n",
            "    Uninstalling protobuf-3.19.6:\n",
            "      Successfully uninstalled protobuf-3.19.6\n",
            "  Attempting uninstall: mkl\n",
            "    Found existing installation: mkl 2019.0\n",
            "    Uninstalling mkl-2019.0:\n",
            "      Successfully uninstalled mkl-2019.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.11.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "googleapis-common-protos 1.58.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-translate 3.8.4 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-language 2.6.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-firestore 2.7.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-datastore 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-bigquery 3.4.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.18.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-api-core 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed coloredlogs-15.0.1 datasets-2.9.0 evaluate-0.4.0 humanfriendly-10.0 mkl-2023.0.0 mkl-include-2023.0.0 multiprocess-0.70.14 onnx-1.12.0 onnxruntime-1.14.0 optimum-1.5.0 protobuf-3.20.1 responses-0.18.0 tbb-2021.8.0 urllib3-1.26.14 xxhash-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import time\n",
        "\n",
        "sentence = 'Royal Bank of Canada is a Canadian multinational financial services company and the largest bank in Canada by market capitalization. The bank serves over 17 million clients and has more than 89,000 employees worldwide'\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2')\n",
        "v_st = time.time() * 1000\n",
        "vanilla_emb = model.encode(sentence)\n",
        "v_et = time.time() * 1000\n",
        "print('time taken for vanilla : {}'.format(v_et - v_st))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFtJAeJOrz18",
        "outputId": "0b19ea62-cddd-4b99-b0fd-6b92c533555d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time taken for vanilla : 107.754638671875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Pipeline\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "# copied from the model card\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "\n",
        "\n",
        "class SentenceEmbeddingPipeline(Pipeline):\n",
        "    def _sanitize_parameters(self, **kwargs):\n",
        "        # we don't have any hyperameters to sanitize\n",
        "        preprocess_kwargs = {}\n",
        "        return preprocess_kwargs, {}, {}\n",
        "\n",
        "    def preprocess(self, inputs):\n",
        "        encoded_inputs = self.tokenizer(inputs, padding=True, truncation=True, return_tensors='pt')\n",
        "        return encoded_inputs\n",
        "\n",
        "    def _forward(self, model_inputs):\n",
        "        outputs = self.model(**model_inputs)\n",
        "        return {\"outputs\": outputs, \"attention_mask\": model_inputs[\"attention_mask\"]}\n",
        "\n",
        "    def postprocess(self, model_outputs):\n",
        "        # Perform pooling\n",
        "        sentence_embeddings = mean_pooling(model_outputs[\"outputs\"], model_outputs['attention_mask'])\n",
        "        # Normalize embeddings\n",
        "        sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
        "        return sentence_embeddings\n"
      ],
      "metadata": {
        "id": "TTufy9L4s_MX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from optimum.onnxruntime import ORTModelForFeatureExtraction\n",
        "from transformers import AutoTokenizer\n",
        "from pathlib import Path\n",
        "\n",
        "onnx_path = Path(\"onnx\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L12-v2')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfZACLhAtSVd",
        "outputId": "76c6ff5d-ab83-467a-fdcb-2f2ef9911f85"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/generation_utils.py:24: FutureWarning: Importing `GenerationMixin` from `src/transformers/generation_utils.py` is deprecated and will be removed in Transformers v5. Import as `from transformers import GenerationMixin` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load optimized model\n",
        "model = ORTModelForFeatureExtraction.from_pretrained(onnx_path, file_name=\"model_optimized_quantized.onnx\")\n",
        "\n",
        "# create optimized pipeline\n",
        "optimized_emb = SentenceEmbeddingPipeline(model=model, tokenizer=tokenizer)\n",
        "\n",
        "o_st = time.time() * 1000\n",
        "optimized_emb_pred = optimized_emb(sentence)\n",
        "o_et =  time.time() * 1000\n",
        "\n",
        "print('time taken for optimized quantized model: {}'.format(o_et - o_st))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kuq4g7rWtxv1",
        "outputId": "9052b999-6e9c-44a6-adfd-8cd5a4a17f3f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time taken for optimized quantized model: 28.317138671875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_emb_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0crb0QZucFq",
        "outputId": "fce1205a-7c7f-4212-a55d-34ed3e832a1e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4.4777e-02,  1.1825e-03,  6.0481e-03, -1.9312e-02,  1.5138e-02,\n",
              "          2.6437e-02,  5.5512e-02,  6.1203e-02,  3.9094e-02,  3.6505e-02,\n",
              "         -1.1903e-01, -4.3564e-03, -2.8887e-02, -5.8724e-02, -5.9878e-02,\n",
              "         -7.5853e-02,  2.1850e-02, -1.5865e-02, -8.2803e-03,  8.5816e-02,\n",
              "         -4.1636e-02, -3.0772e-02, -4.2817e-03, -2.1819e-02,  3.4203e-02,\n",
              "         -3.7289e-02, -6.9369e-02,  2.1012e-02,  1.1867e-03, -2.0010e-02,\n",
              "          2.0115e-02,  2.4797e-02,  1.5249e-02,  6.2365e-02, -1.3636e-02,\n",
              "          9.1422e-02, -7.4480e-02, -1.1528e-02,  1.8219e-03,  2.6597e-02,\n",
              "         -1.6901e-02,  5.8106e-03, -7.0798e-03, -3.7733e-02,  6.6445e-02,\n",
              "          2.9531e-02, -1.1449e-01,  3.1857e-02, -6.7084e-02,  7.9999e-02,\n",
              "          5.5763e-02, -7.1333e-02,  4.5483e-02, -8.2652e-02,  2.4699e-02,\n",
              "         -1.7799e-02, -4.5248e-02, -5.9049e-02,  6.9176e-02,  1.4136e-02,\n",
              "          1.1544e-01,  4.0786e-02,  1.0315e-02,  3.1071e-02,  8.1621e-02,\n",
              "          3.9502e-02,  5.0360e-02,  8.7738e-02, -1.6404e-02, -1.0141e-01,\n",
              "         -1.4905e-03, -4.7007e-02, -1.5649e-02,  2.9831e-02, -6.2536e-02,\n",
              "         -1.3157e-02,  1.9641e-02,  4.7977e-02, -2.3611e-02,  9.8558e-03,\n",
              "          4.1469e-02, -1.5632e-02,  3.6227e-02, -2.6139e-02,  4.2896e-02,\n",
              "         -5.5734e-02, -1.1287e-03,  5.8703e-03, -6.3108e-02,  6.3599e-03,\n",
              "          1.0906e-02,  5.9022e-02,  1.7158e-02, -1.2560e-02, -1.6222e-02,\n",
              "         -4.3349e-02,  6.4553e-02, -3.5170e-02, -1.4990e-02,  1.3224e-02,\n",
              "          1.3327e-02,  7.2107e-02,  1.0765e-01,  1.1151e-02, -7.1269e-02,\n",
              "         -3.9205e-03, -1.6778e-02,  7.9400e-02,  1.4075e-01, -1.1116e-01,\n",
              "          4.8824e-03,  1.3829e-02,  1.0974e-02, -8.0603e-02,  3.2684e-02,\n",
              "         -2.7355e-03, -5.1469e-02,  3.5435e-02,  5.6815e-02,  1.2555e-01,\n",
              "         -3.0121e-02,  1.2360e-01, -1.0059e-01, -2.8105e-02, -7.9956e-02,\n",
              "          3.5754e-02, -5.8956e-02,  3.4883e-02, -1.2357e-01,  3.4985e-02,\n",
              "         -2.4466e-02,  2.2246e-02, -6.0913e-02, -2.9930e-02, -2.4071e-02,\n",
              "          4.7930e-02,  4.0145e-02,  5.2403e-02,  3.8596e-02,  2.7347e-03,\n",
              "          6.5685e-03,  9.4608e-03,  3.3439e-02,  3.3685e-04, -7.3827e-02,\n",
              "          1.5397e-02, -6.4958e-02,  8.7017e-02,  3.4254e-02,  2.3836e-02,\n",
              "         -5.2151e-02,  1.0476e-01,  3.1068e-02, -7.4641e-02, -9.8973e-02,\n",
              "         -4.9362e-02,  5.2522e-02, -2.4553e-02,  6.2871e-03, -6.6671e-02,\n",
              "          3.6193e-02,  2.6302e-02,  9.9476e-02,  1.4951e-02, -1.7065e-03,\n",
              "         -5.9608e-02,  5.4874e-02,  6.3122e-03, -8.4681e-02,  3.5666e-02,\n",
              "          4.0755e-02, -1.2409e-02,  6.8690e-03,  6.8899e-02, -2.0058e-03,\n",
              "         -3.9369e-02, -3.9719e-02,  2.7915e-02,  2.8945e-03,  2.9352e-02,\n",
              "         -1.1379e-01,  7.9178e-02,  9.0864e-02, -3.2165e-02, -4.0217e-02,\n",
              "          9.0343e-02,  2.0321e-02,  3.2227e-02,  5.3274e-02, -6.3153e-03,\n",
              "         -4.9613e-02,  5.9221e-02, -1.6783e-02,  7.9324e-02,  6.6108e-02,\n",
              "         -5.3418e-02, -2.2109e-02, -1.7399e-03, -4.0347e-02,  4.3603e-02,\n",
              "          8.1050e-02,  1.2937e-02, -2.0193e-02,  2.4310e-02, -3.2418e-02,\n",
              "          4.3471e-02,  3.3989e-02, -4.8885e-03, -4.3876e-02,  2.8231e-03,\n",
              "          7.3470e-02, -4.4905e-02,  2.9306e-02,  9.6869e-02,  3.8579e-02,\n",
              "         -8.7841e-02, -3.9760e-02,  1.8373e-02,  1.0296e-02, -2.0693e-02,\n",
              "         -1.5182e-02,  8.8505e-03, -3.3908e-02,  2.7938e-34, -4.0742e-02,\n",
              "         -2.1701e-02,  3.6898e-02,  1.6228e-02, -2.0458e-02, -2.2618e-03,\n",
              "          8.6417e-02,  1.6638e-02,  2.1290e-02, -3.6172e-02,  5.5552e-02,\n",
              "         -7.4259e-03, -5.2191e-02, -1.9872e-02,  7.9802e-02, -2.3472e-02,\n",
              "         -2.9170e-03, -4.4256e-02, -1.0184e-01, -3.1146e-02, -3.5456e-02,\n",
              "         -8.2132e-02,  8.8867e-02,  4.8170e-02,  4.4730e-02,  1.4285e-02,\n",
              "         -4.9134e-02, -5.3853e-02,  5.0327e-02, -1.1432e-01, -2.0499e-02,\n",
              "          5.0785e-02, -1.2424e-02,  6.1133e-02, -5.3378e-02, -4.0880e-02,\n",
              "         -2.9999e-03, -3.7594e-02,  7.0847e-02,  4.1598e-02,  1.0638e-02,\n",
              "         -4.8920e-02,  1.5111e-02, -7.7051e-02, -3.5246e-02,  2.4542e-02,\n",
              "          1.3409e-02,  6.6078e-03, -1.7247e-03, -2.9586e-02, -3.5390e-02,\n",
              "         -1.4223e-02, -7.0035e-02, -2.9836e-02, -9.1627e-02,  1.0122e-01,\n",
              "          6.4463e-02,  3.1410e-02,  2.6073e-02, -4.4058e-03,  3.9613e-02,\n",
              "         -4.7443e-02,  8.2406e-02,  4.9675e-02,  1.1245e-02,  2.7229e-02,\n",
              "          2.3577e-02,  4.1234e-02,  1.3480e-02, -7.4196e-02, -1.6506e-02,\n",
              "          5.8696e-03, -2.9587e-02,  1.6201e-02, -5.6286e-02,  3.3976e-02,\n",
              "         -3.9132e-02, -8.5046e-02, -3.0131e-03, -9.7214e-03, -3.6518e-02,\n",
              "          6.4448e-02, -6.2864e-02,  4.0072e-02, -3.2440e-03,  2.7706e-03,\n",
              "          2.7272e-02, -9.9620e-02, -2.9245e-02,  1.6080e-03, -8.7039e-02,\n",
              "         -5.2287e-02, -3.6046e-02, -4.6994e-02, -1.6451e-02,  5.3675e-32,\n",
              "          1.0276e-02, -4.4468e-02, -7.3000e-02,  5.2753e-04,  1.8836e-02,\n",
              "         -8.1422e-02, -1.7254e-03,  3.2289e-02, -9.0592e-02, -1.3609e-02,\n",
              "          2.6876e-02,  2.9042e-02, -3.8509e-02, -3.3538e-02,  2.3214e-02,\n",
              "         -4.4929e-02, -1.0267e-01, -4.5217e-02,  1.6857e-02, -3.5326e-02,\n",
              "         -7.2688e-02, -6.8594e-03,  5.7195e-02,  1.5251e-02, -2.8783e-02,\n",
              "         -1.1857e-01,  3.3509e-02,  3.8760e-02,  4.7159e-02, -6.2820e-02,\n",
              "          6.9919e-02, -1.8719e-02, -8.8389e-02, -2.2354e-02,  8.7478e-02,\n",
              "          1.7942e-03,  5.8327e-02,  5.7437e-03,  3.3314e-02, -1.8336e-02,\n",
              "          2.1068e-02,  3.9993e-03, -7.5731e-02,  3.4245e-02, -1.9104e-02,\n",
              "         -8.5241e-02, -9.7632e-02,  1.2974e-01, -1.9666e-02, -7.1989e-03,\n",
              "         -2.5364e-02, -1.2935e-02,  9.5451e-02,  9.6724e-02,  1.8589e-02,\n",
              "          1.8527e-02, -1.8477e-02, -8.9977e-02,  1.2385e-02, -8.5400e-02,\n",
              "         -3.4395e-02, -3.6074e-02,  4.5477e-02, -5.0045e-02]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "r_8TNwo3uj3R"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarity([vanilla_emb],optimized_emb_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nr3ytBY_ur_9",
        "outputId": "eb8417ae-be13-4bdf-8326-d7e815d6be41"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.97197986]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7jZXFtQbuz13"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}